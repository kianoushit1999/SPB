from dotenv import load_dotenv
from agents import Agent, Runner, function_tool
import gradio as gr
from pydantic import BaseModel, Field
import math
import json
from openai import OpenAI
import base64
from io import BytesIO
from PIL import Image
from google import genai
from google.genai import types
from typing import Dict
import asyncio

load_dotenv(override=True)
client = genai.Client(api_key=GEMINI_API_KEY)

question_index = 0
repeat_question = False
accepted_answers = []

questionsList = [
        'Ø³Ù† Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',
        'Ø¬Ù†Ø³ÛŒØª Ø´Ù…Ø§ Ú†Ù‡ Ù…ÛŒØ¨Ø§Ø´Ø¯ØŸ(Ù…Ø±Ø¯ / Ø²Ù†)',
        'Ø¢Ø®Ø±ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©/Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø´Ù…Ø§ Ú†Ù†Ø¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ',
        'Ø±Ú˜ÛŒÙ… ØºØ°Ø§ÛŒÛŒ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø´ÙˆØ± Ø§Ø³ØªØŸ (Ú©Ù… / Ù…ØªÙˆØ³Ø· / Ø²ÛŒØ§Ø¯)',
        'Ø¢ÛŒØ§ Ø¨Ù‡ ØºØ°Ø§ÛŒ Ø®ÙˆØ¯ Ù†Ù…Ú© Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒÚ©Ù†ÛŒØ¯ØŸ',
        'Ú†Ù†Ø¯ Ø¨Ø§Ø± Ø¯Ø± Ù‡ÙØªÙ‡ ØºØ°Ø§Ù‡Ø§ÛŒ Ù¾Ø±Ù†Ù…Ú© Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯ØŸ',
        'Ø±ÙˆØ²Ø§Ù†Ù‡ Ú†Ù†Ø¯ Ù„ÛŒÙˆØ§Ù† Ø¢Ø¨ Ù…ÛŒÙ†ÙˆØ´ÛŒØ¯ØŸ',
        'Ø¢ÛŒØ§ Ù†ÙˆØ´Ø§Ø¨Ù‡ ÛŒØ§ Ù‚Ù‡ÙˆÙ‡ Ø²ÛŒØ§Ø¯ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯ØŸ',
        'Ú†Ù‚Ø¯Ø± ÙˆØ±Ø²Ø´ Ù…ÛŒÚ©Ù†ÛŒØ¯ ØŸ(Ù‡ÛŒÚ† / Ù‡ÙØªÙ‡ Û±-Û² Ø¨Ø§Ø± / Ù…Ù†Ø¸Ù…)',
        'Ù‚Ø¯ ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',
        'ÙˆØ²Ù† ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',
        'Ø¢ÛŒØ§ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø¯Ø§Ø±ÛŒØ¯ØŸ',
        'Ú†Ù‡ Ø¯Ø§Ø±ÙˆÛŒÛŒ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯',
        'Ø¢ÛŒØ§ Ø¯Ø± Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ ØªØ§Ù† Ú©Ø³ÛŒ ÙØ´Ø§Ø±Ø®ÙˆÙ† ÛŒØ§ Ø³Ú©ØªÙ‡ Ú©Ø±Ø¯Ù‡ Ø§Ø³ØªØŸ',
        'Ø³Ø·Ø­ Ø§Ø³ØªØ±Ø³ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',
        'Ø¢ÛŒØ§ Ø³ÛŒÚ¯Ø§Ø± ÛŒØ§ Ø§Ù„Ú©Ù„ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯ØŸ',
    ]

def generate_user_info_instructions():
    global question_index, repeat_question

    return f'''
        You are an interviewer agent who is communicating in persian. Asking the question at once.

        Your goal is to find the answer of question.
        You must:
        1. Ask one question at a time
        2. Wait for the user's answer
        3. Validate if the answer is acceptable
        4. If invalid â†’ ask that question again politely to get its related answer.
        5. If valid â†’ store it and ask the next question


        You MUST NOT produce the final structured output until all fields are collected.
        Required questions (ask in Persian):
        {questionsList[question_index]}

        {f'You must say in more polite way that your previous answer is wrong and explain the {questionsList[question_index]} in more detail' if repeat_question else ''}

        - is_question_being_answered:
            true â†’ only if the user's message is a valid answer to the current question. You need to checkout the response to be completely rational not to be everything.
            false â†’ if the answer is invalid, irrelevant, empty, or incomplete.

        - accepted_user_response:
            If the answer is valid â†’ return the raw user message.
            If invalid â†’ return an empty string "".

        - agent_response:
            This is the text you want to send back to the user. Checkout the response to be rationally acceptable.
            If valid â†’ say your answer being confirmed.
            If invalid â†’ politely explain the mistake and ask the same question again.

        ** Crusial: if is_question_being_answered is true then 
    '''

class UserInfo(BaseModel):
    is_question_being_answered: bool = Field(description="Whether the question's answer is accpeted or not")
    accepted_user_response: str = Field(description="The user's response which was accepted")
    agent_response: str = Field(description="The response of the agent")

def call_interviewer_agent():
    agent_interviewer = Agent(
        name="Interviewer",
        instructions=generate_user_info_instructions(),
        model="gpt-4o",
        output_type = UserInfo
    )
    return agent_interviewer

class KBloodPressure(BaseModel):
    K: int = Field(description="calculated k")

K_INSTRUCTIONS = '''

- K is 5 for normal users (low risk) and 10 for users who are high-risk (e.g., history of high blood pressure, salt-sensitive, sedentary, smoker, family history, high salt diet).
- Only output 5 or 10.
- Use the answers to relevant questions to assess risk:
    - 'Ø¢Ø®Ø±ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©/Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø´Ù…Ø§ Ú†Ù†Ø¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ'
    - 'Ø¢ÛŒØ§ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø¯Ø§Ø±ÛŒØ¯ØŸ'
    - 'Ø±Ú˜ÛŒÙ… ØºØ°Ø§ÛŒÛŒ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø´ÙˆØ± Ø§Ø³ØªØŸ'
    - 'Ú†Ù‚Ø¯Ø± ÙˆØ±Ø²Ø´ Ù…ÛŒÚ©Ù†ÛŒØ¯ ØŸ'
    - 'Ø¢ÛŒØ§ Ø³ÛŒÚ¯Ø§Ø± ÛŒØ§ Ø§Ù„Ú©Ù„ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯ØŸ'
    - 'Ø¢ÛŒØ§ Ø¯Ø± Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ ØªØ§Ù† Ú©Ø³ÛŒ ÙØ´Ø§Ø±Ø®ÙˆÙ† ÛŒØ§ Ø³Ú©ØªÙ‡ Ú©Ø±Ø¯Ù‡ Ø§Ø³ØªØŸ'
- K is needed for calculating the effect of salt on blood pressure.
'''

k_agent = Agent(
    name = 'k-finder', 
    instructions = K_INSTRUCTIONS,
    model = 'gpt-4o',
    output_type = KBloodPressure
)

def clamp_to_range(value: float | int) -> int:
    """
    Force a number into the inclusive range [105, 180].
    Returns an *int* (you can change to float if you need decimals).
    """
    return max(105, min(180, int(value)))

@function_tool
def calculate_blood_pressure(k: int, SBP_current: int):

    ten_percent_more_salt_SBP_new = clamp_to_range(SBP_current + k*math.log(1.1))
    current_SBP_new = clamp_to_range(SBP_current + k*math.log(1))
    ten_percent_less_salt_SBP_new = clamp_to_range(SBP_current + k*math.log(0.9 ))

    return {
        'SBP_new': {
            'ten_percent_more_salt': ten_percent_more_salt_SBP_new,
            'current': current_SBP_new,
            'ten_percent_less_salt': ten_percent_less_salt_SBP_new
        }
    }

@function_tool
def predict_blood_pressure(SBP_current: int, SBP_new_ten_precent_more: int, SBP_new_current: int, SBP_new_ten_percent_less: int):
    '''
        Calculate the blood pressure after 30 days based on the:
        SBP(t) = SBP_base + Î”SBP Ã— (1 - e^( -t / Ï„ ))
    '''
    SBP_base = SBP_current
    delta_SBP = SBP_new_ten_precent_more - SBP_current
    tau = 10
    t = 30

    predicted_SBP_new_ten_precent_more = clamp_to_range(SBP_base + delta_SBP * (1 - pow(math.e, -t / tau)))

    delta_SBP = SBP_new_current - SBP_current
    predicted_SBP_new_current = clamp_to_range(SBP_base + delta_SBP * (1 - pow(math.e, -t / tau)))

    delta_SBP = SBP_new_ten_percent_less - SBP_current
    predicted_SBP_new_ten_percent_less = clamp_to_range(SBP_base + delta_SBP * (1 - pow(math.e, -t / tau)))

    return {
        'SBP_predicted': {
            'ten_percent_more_salt': predicted_SBP_new_ten_precent_more,
            'current': predicted_SBP_new_current,
            'ten_percent_less_salt': predicted_SBP_new_ten_percent_less
        }
    }

k_agent_tool = k_agent.as_tool(tool_name='k_agent_tool', tool_description='finding k for calculating the effect of salt on bool pressure')
tools = [k_agent_tool, calculate_blood_pressure, predict_blood_pressure]

def generate_BP_expert_instruction():
    return '''
        You are a Blood Pressure Expert AI. Your goal is to help estimate and predict a patient's systolic blood pressure (SBP) under different scenarios of salt intake over 30 days. 

        You have access to the following tools:

        1. "k_agent_tool": Use this tool to determine the sensitivity parameter K based on the patient's information. K can only be 5 (normal) or 10 (hypertensive or salt-sensitive). K is needed for calculating the effect of salt on blood pressure.

        2. "calculate_blood_pressure": Use this tool to calculate the patient's new SBP immediately after changes in salt intake. This tool takes K and the current SBP and provides SBP values for three scenarios:
        - Ten percent more salt
        - Current salt intake
        - Ten percent less salt

        3. "predict_blood_pressure": Use this tool to predict the SBP after 30 days for each scenario using a dynamic model:
        SBP(t) = SBP_base + Î”SBP Ã— (1 - e^(-t / Ï„))

        Instructions:

        - Always start by using "k_agent_tool" to determine K from the patient's answers.
        - Then use "calculate_blood_pressure" with input parameter of K which is calculated in previous state and the patient's current SBP based on the answer of the question of 'Ø¢Ø®Ø±ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©/Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø´Ù…Ø§ Ú†Ù†Ø¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ'.
        - Finally, use "predict_blood_pressure" to calculate the SBP after 30 days for each scenario. The inputs of predict_blood_pressure are the following:
            - SBP_current: based on the answer of question 'Ø¢Ø®Ø±ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©/Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø´Ù…Ø§ Ú†Ù†Ø¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ'
            - SBP_new_ten_precent_more, SBP_new_current, SBP_new_ten_percent_less are the Immediate SBP which was calculated in predict_blood_pressure
        - Be precise and only use the tools for calculations; do not guess numeric values.
        - Output should clearly show in a json format and do not add further any words and sentences :
            - calculated K with the name of k in the output json
            - SBP_base which was used in all of the tools with SBP_base in the output json
            - Immediate SBP for each scenario based on function of calculate_blood_pressure (the name of output should not change at all and should be SBP_new )
            - Predicted SBP after 30 days for each scenario based on the output of predict_blood_pressure (the name of output should not change at all and must be SBP_predicted)

        Patient inputs you may receive include current SBP and any relevant health/salt-sensitivity information.

    '''

def call_blood_pressure_expert():
    blood_pressure_expert_agent = Agent(
        name = 'blood_pressure_expert',
        instructions= generate_BP_expert_instruction(),
        model="gpt-4o",
        tools = tools
    )

    return blood_pressure_expert_agent

async def call_SBP_expert_agent() -> Dict[str, str]:
    global questionsList, accepted_answers
    prompt = ''
    for question, ans in zip(questionsList, accepted_answers):
        prompt += f'{question}: {ans}\\n'

    prompt += """
        Please determine:
        1) K (5 for normal, 10 if patient has high blood pressure or is salt-sensitive).
        2) Immediate_SBP for three salt scenarios: 10% less, current, 10% more.
        3) Predicted SBP after 30 days for each scenario.
        Return results clearly labeled.
    """

    predictor_agent = call_blood_pressure_expert()
    result = await Runner.run(predictor_agent, prompt)
    raw_text = result.final_output
    print(raw_text)
    return json.loads(raw_text.replace('```json', '').replace('```', '').strip())

def generate_chart_image_generator_instruction(immediate_SBP, predicted_SBP):
    CHART_IMAGE_GENERATOR_INSTRUCTION = f'''
        You are a strict and highly precise chart-rendering agent. Your task is to generate a clean, accurate data-visualization image consisting of THREE SEPARATE LINE-CHART PANELS stacked vertically:

    1. Panel 1: "10% Less"
    2. Panel 2: "Current"
    3. Panel 3: "10% More"

    Each panel represents ONE scenario only.

    You MUST use ONLY the numerical values provided in two structured inputs:
    - immediate_SBP = {{ 'ten_percent_less': {immediate_SBP['ten_percent_less_salt']}, 'actual (current)': {immediate_SBP['current']}, 'ten_percent_more': {immediate_SBP['ten_percent_more_salt']} }}
    - predicted_SBP = {{ 'ten_percent_less': {predicted_SBP['ten_percent_less_salt']}, 'actual (current)': {predicted_SBP['current']}, 'ten_percent_more': {predicted_SBP['ten_percent_more_salt']} }}

    ------------------------------------------------------------
    OVERALL VISUAL DESIGN (applies to all 3 panels)
    ------------------------------------------------------------
    â€¢ All three charts must have the SAME:
    - Y-axis label: "SBP (mmHg)"
    - X-axis categories: "Day 0" (start), "Day 30" (end)
    - Horizontal scale range: Auto-scale but must include both values.
    â€¢ Style: Very clean, minimal, medical-grade professional.
    â€¢ Line: Smooth, thin, with circular markers at both data points.
    â€¢ Value labels MUST appear next to both data points.
    â€¢ Colors:
    - 10% Less â†’ Green
    - Current â†’ Blue
    - 10% More â†’ Red
    â€¢ No extra gridlines besides major axis lines.

    ------------------------------------------------------------
    PANEL RULES (for each of the 3 diagrams)
    ------------------------------------------------------------

    ### PANEL 1 â†’ "10% Less"  
    â€¢ Start at SBP = immediate_SBP.ten_percent_less  
    â€¢ End at SBP = predicted_SBP.ten_percent_less  
    â€¢ Draw a SINGLE line connecting Day 0 â†’ Day 30.
    â€¢ Color: Green.
    â€¢ Title the panel: "10% Less SBP Scenario".

    ### PANEL 2 â†’ "Current"  
    â€¢ Start at SBP = immediate_SBP.current  
    â€¢ End at SBP = predicted_SBP.current  
    â€¢ Draw a SINGLE line connecting Day 0 â†’ Day 30.
    â€¢ Color: Blue.
    â€¢ Title the panel: "Current SBP Scenario".

    ### PANEL 3 â†’ "10% More"
    â€¢ Start at SBP = immediate_SBP.ten_percent_more  
    â€¢ End at SBP = predicted_SBP.ten_percent_more  
    â€¢ Draw a SINGLE line connecting Day 0 â†’ Day 30.
    â€¢ Color: Red.
    â€¢ Title the panel: "10% More SBP Scenario".

    ------------------------------------------------------------
    STRICT ACCURACY REQUIREMENTS
    ------------------------------------------------------------
    â€¢ You must plot EXACT given numerical values â€” no smoothing, no rounding.
    â€¢ The Y-axis must reflect the true distance between immediate vs. predicted.
    â€¢ If the SBP rises, line slopes upward; if it falls, slope downward; if equal, line is horizontal.
    â€¢ Do NOT merge scenarios into one chart. Each panel = one scenario only.
    â€¢ Panels must be visually parallel and uniformly sized.

    ------------------------------------------------------------
    OUTPUT REQUIREMENT
    ------------------------------------------------------------
    Produce ONE final image that contains all three panels aligned vertically in the order:
    1. 10% Less  
    2. Current  
    3. 10% More  

    It must look like a medical-grade report visualization: clean, aligned, precise.

    '''

    return CHART_IMAGE_GENERATOR_INSTRUCTION

def digital_twin_image_prompt_generator():
    global accepted_answers, question_list
    DIGITAL_TWIN_IMAGE_PROMPT_INSTRUCTIONS = '''
        You are the **Digital Twin Image-Prompt Generator Agent**.

        Your job:
        - Receive the user's interview answers (age, gender, height, weight, BMI, baseline SBP, salt intake, activity level, smoking/alcohol, stress, family history, medications, current_SBP).
        - Analyze all values and convert them into **digital-twin parameters**.
        - Then produce a **complete and final image-generation prompt** for an external image generator model.

        ### 1. Processing Rules
        - Calculate BMI = weight / (height in meters)^2
        - Assign a **risk color** for the human silhouette:
        - Green = low risk
        - Yellow = moderate risk
        - Red = high risk
        - Create three surrounding rings:
        1. Salt ring â†’ intensity based on salt intake + added salt + salty food frequency
        2. Weight ring â†’ intensity based on BMI category
        3. Activity ring â†’ intensity based on physical activity level
        - Predict SBP trend (simple rules):
        - High salt or no activity â†’ predicted SBP increases
        - Healthy habits â†’ predicted SBP decreases or stays stable

        ### 2. Image Prompt Requirements
        You must output **only the final image prompt**, describing:

        - A human digital silhouette ("digital twin")
        - The silhouette's color showing the total cardiovascular risk
        - Three circular rings around the figure:
        - Salt ring
        - Weight ring
        - Activity ring
        - Each ring's brightness/thickness scales with the user's risk levels
        - Display text labels with:
        - Age
        - Gender
        - BMI (calculated)
        - Current SBP
        - Predicted SBP
        - Style:
        - Clean
        - Modern medical infographic
        - High contrast
        - Soft glow effects around rings

        ### 3. Output Format
        ALWAYS output only the **image prompt**, nothing else.

        The output is meant to be fed directly into an image generation model.

    '''
    digital_twin_image_prompt_agent = Agent(
        name='image_prompt_generator_agent',
        model='gpt-4o',
        instructions = DIGITAL_TWIN_IMAGE_PROMPT_INSTRUCTIONS,
    )

    return digital_twin_image_prompt_agent

async def gemini_image_generator_async(prompt):
    def sync_generate():
        response = client.models.generate_content(
            model="gemini-2.5-flash-image",
            contents=prompt,
            config=types.GenerateContentConfig(response_modalities=[types.Modality.IMAGE])
        )
        image_bytes = response.candidates[0].content.parts[0].inline_data.data
        return Image.open(BytesIO(image_bytes))
    return await asyncio.to_thread(sync_generate)

WATCH_FILM_MESSAGE = "Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ± ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ ØªÙ…Ø§Ø´Ø§ Ú©Ù†ÛŒØ¯."

async def chat(message, history):
    global question_index, repeat_question

    history = history or []

    agent_interviewer = call_interviewer_agent()
    result = await Runner.run(agent_interviewer, message)

    print(result.final_output)

    chart_image = None
    digital_twin_image = None

    if (result.final_output.is_question_being_answered):
        question_index += 1
        repeat_question = False
        accepted_answers.append(result.final_output.accepted_user_response)
        if question_index == len(questionsList):
            agent_reply = (
                        str(result.final_output.agent_response)
                        + '\\n'
                        + f'{WATCH_FILM_MESSAGE}'
                    )

            json_SBP = await call_SBP_expert_agent()
            print(json_SBP)
            immediate_SBP = json_SBP['SBP_new']
            predicted_SBP = json_SBP['SBP_predicted']
            print(immediate_SBP, predicted_SBP)

            chart_image_generator_agent = digital_twin_image_prompt_generator()
            prompt = 'These are the questions and answers of interview: \\n'
            for question, ans in zip(questionsList, accepted_answers):
                prompt += f'{question}: {ans}\\n'
            image_prompt = await Runner.run(chart_image_generator_agent, prompt)
            chart_image, digital_twin_image = await asyncio.gather(gemini_image_generator_async(generate_chart_image_generator_instruction(immediate_SBP, predicted_SBP)), gemini_image_generator_async(image_prompt.final_output))


        else:
            agent_reply = str(result.final_output.agent_response) + '\n' + f'{questionsList[question_index]}'
    else:
        repeat_question = True
        agent_reply = str(result.final_output.agent_response)

    history.append((message, agent_reply))

    video_url = ''
    if (question_index == len(questionsList)):
        video_url = 'https://www.aparat.com/video/video/embed/videohash/pl2Ww/vt/frame'

    video_output = f"""<div style="width:100%; height:400px;">
                            <iframe
                                style="width:100%; height:100%; border:0;"
                                src="{video_url}"
                                allowfullscreen>
                            </iframe>
                        </div>
                    """    

    return history, "", video_output, chart_image, digital_twin_image

def reset_all():
    global question_index, repeat_question, accepted_answers
    question_index = 0
    repeat_question = False
    accepted_answers = []

    return "", "", "", None, None

with gr.Blocks() as demo:
    gr.Markdown("<h1 style='text-align:center; direction:rtl;'>ğŸ§  Ø¯Ø³ØªÛŒØ§Ø± Ù…ØµØ§Ø­Ø¨Ù‡ Ø³Ù„Ø§Ù…Øª</h1>")

    with gr.Row():
        with gr.Column(scale=2):
            chatbot = gr.Chatbot(label="Ú¯ÙØªÚ¯Ùˆ", rtl=True)
            msg = gr.Textbox(label="Ù¾ÛŒØ§Ù… Ø´Ù…Ø§", placeholder="Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯...", rtl=True)
            reset_btn = gr.Button("ğŸ”„ Ø±ÛŒØ³Øª")
    with gr.Row():
        chart_image = gr.Image(label="ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± ÙØ´Ø§Ø± Ø®ÙˆÙ†")
        video_output = gr.HTML(label="ÙˆÛŒØ¯ÛŒÙˆ")
        digital_twin_image = gr.Image(label="ğŸ§â™‚ï¸ ØªØµÙˆÛŒØ± Ø¯ÛŒØ¬ÛŒØªØ§Ù„ ØªÙˆØ¦ÛŒÙ†")
    
            

    # Message submit
    msg.submit(
        chat,
        [msg, chatbot],
        [chatbot, msg, video_output, chart_image, digital_twin_image]
    )

    # Reset button click
    reset_btn.click(
        reset_all,
        inputs=[],
        outputs=[chatbot, msg, video_output, chart_image, digital_twin_image]
    )

if __name__ == "__main__":
    demo.launch()
