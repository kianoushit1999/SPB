{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d08d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, function_tool\n",
    "import gradio as gr\n",
    "from pydantic import BaseModel, Field\n",
    "import math\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from typing import Dict\n",
    "import asyncio\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30567c91",
   "metadata": {},
   "source": [
    "## Load API KEYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75c0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f790ac7f",
   "metadata": {},
   "source": [
    "## Defining question and answer list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2299156",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_index = 0\n",
    "repeat_question = False\n",
    "accepted_answers = []\n",
    "\n",
    "questionsList = [\n",
    "        'Ø³Ù† Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',\n",
    "        'Ø¬Ù†Ø³ÛŒØª Ø´Ù…Ø§ Ú†Ù‡ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯ØŸ(Ù…Ø±Ø¯ / Ø²Ù†)',\n",
    "        'Ø¢Ø®Ø±ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©/Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø´Ù…Ø§ Ú†Ù†Ø¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ',\n",
    "        'Ø±Ú˜ÛŒÙ… ØºØ°Ø§ÛŒÛŒ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø´ÙˆØ± Ø§Ø³ØªØŸ (Ú©Ù… / Ù…ØªÙˆØ³Ø· / Ø²ÛŒØ§Ø¯)',\n",
    "        'Ø¢ÛŒØ§ Ø¨Ù‡ ØºØ°Ø§ÛŒ Ø®ÙˆØ¯ Ù†Ù…Ú© Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŸ',\n",
    "        'Ú†Ù†Ø¯ Ø¨Ø§Ø± Ø¯Ø± Ù‡ÙØªÙ‡ ØºØ°Ø§Ù‡Ø§ÛŒ Ù¾Ø±Ù†Ù…Ú© Ù…ØµØ±Ù Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŸ',\n",
    "        'Ø±ÙˆØ²Ø§Ù†Ù‡ Ú†Ù†Ø¯ Ù„ÛŒÙˆØ§Ù† Ø¢Ø¨ Ù…ÛŒâ€ŒÙ†ÙˆØ´ÛŒØ¯ØŸ',\n",
    "        'Ø¢ÛŒØ§ Ù†ÙˆØ´Ø§Ø¨Ù‡ ÛŒØ§ Ù‚Ù‡ÙˆÙ‡ Ø²ÛŒØ§Ø¯ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯ØŸ',\n",
    "        'Ú†Ù‚Ø¯Ø± ÙˆØ±Ø²Ø´ Ù…ÛŒÚ©Ù†ÛŒØ¯ ØŸâ€Œ(Ù‡ÛŒÚ† / Ù‡ÙØªÙ‡ Û±-Û² Ø¨Ø§Ø± / Ù…Ù†Ø¸Ù…)',\n",
    "        'Ù‚Ø¯ ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',\n",
    "        'ÙˆØ²Ù† ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',\n",
    "        'Ø¢ÛŒØ§ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø¯Ø§Ø±ÛŒØ¯ØŸ',\n",
    "        'Ú†Ù‡ Ø¯Ø§Ø±ÙˆÛŒÛŒ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯',\n",
    "        'Ø¢ÛŒØ§ Ø¯Ø± Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ ØªØ§Ù† Ú©Ø³ÛŒ ÙØ´Ø§Ø±Ø®ÙˆÙ† ÛŒØ§ Ø³Ú©ØªÙ‡ Ú©Ø±Ø¯Ù‡ Ø§Ø³ØªØŸ',\n",
    "        'Ø³Ø·Ø­ Ø§Ø³ØªØ±Ø³ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',\n",
    "        'Ø¢ÛŒØ§ Ø³ÛŒÚ¯Ø§Ø± ÛŒØ§ Ø§Ù„Ú©Ù„ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯ØŸ',\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425d6e7",
   "metadata": {},
   "source": [
    "## Define User Info Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6092416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_info_instructions():\n",
    "    global question_index, repeat_question\n",
    "\n",
    "    return f'''\n",
    "        You are an interviewer agent who is communicating in persian. Asking the question at once.\n",
    "\n",
    "        Your goal is to find the answer of question.\n",
    "        You must:\n",
    "        1. Ask one question at a time\n",
    "        2. Wait for the user's answer\n",
    "        3. Validate if the answer is acceptable\n",
    "        4. If invalid â†’ ask that question again politely to get its related answer.\n",
    "        5. If valid â†’ store it and ask the next question\n",
    "\n",
    "\n",
    "        You MUST NOT produce the final structured output until all fields are collected.\n",
    "        Required questions (ask in Persian):\n",
    "        {questionsList[question_index]}\n",
    "\n",
    "        {f'You must say in more polite way that your previous answer is wrong and explain the {questionsList[question_index]} in more detail' if repeat_question else ''}\n",
    "\n",
    "        - is_question_being_answered:\n",
    "            true â†’ only if the user's message is a valid answer to the current question. You need to checkout the response to be completely rational not to be everything.\n",
    "            false â†’ if the answer is invalid, irrelevant, empty, or incomplete.\n",
    "\n",
    "        - accepted_user_response:\n",
    "            If the answer is valid â†’ return the raw user message.\n",
    "            If invalid â†’ return an empty string \"\".\n",
    "\n",
    "        - agent_response:\n",
    "            This is the text you want to send back to the user. Checkout the response to be rationally acceptable.\n",
    "            If valid â†’ say your answer being confirmed.\n",
    "            If invalid â†’ politely explain the mistake and ask the same question again.\n",
    "\n",
    "        ** Crusial: if is_question_being_answered is true then \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9faadff",
   "metadata": {},
   "source": [
    "## Define interview Agent output Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "678084fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInfo(BaseModel):\n",
    "    is_question_being_answered: bool = Field(description=\"Whether the question's answer is accpeted or not\")\n",
    "    accepted_user_response: str = Field(description=\"The user's response which was accepted\")\n",
    "    agent_response: str = Field(description=\"The response of the agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea603a2",
   "metadata": {},
   "source": [
    "## Define Agent Interviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "07efe80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_interviewer_agent():\n",
    "    agent_interviewer = Agent(\n",
    "        name=\"Interviewer\",\n",
    "        instructions=generate_user_info_instructions(),\n",
    "        model=\"gpt-4o\",\n",
    "        output_type = UserInfo\n",
    "    )\n",
    "    return agent_interviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0badfa",
   "metadata": {},
   "source": [
    "## Risk Assessment Factor (K-Value)\n",
    "### Define K-Value Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "7f2d5b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KBloodPressure(BaseModel):\n",
    "    K: int = Field(description=\"calculated k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_INSTRUCTIONS = '''\n",
    "- K is 5 for normal users (low risk) and 10 for users who are high-risk (e.g., history of high blood pressure, salt-sensitive, sedentary, smoker, family history, high salt diet).\n",
    "- Only output 5 or 10.\n",
    "- Use the answers to relevant questions to assess risk:\n",
    "    - 'Ø¢Ø®Ø±ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©/Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø´Ù…Ø§ Ú†Ù†Ø¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ'\n",
    "    - 'Ø¢ÛŒØ§ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø¯Ø§Ø±ÛŒØ¯ØŸ'\n",
    "    - 'Ø±Ú˜ÛŒÙ… ØºØ°Ø§ÛŒÛŒ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø´ÙˆØ± Ø§Ø³ØªØŸ'\n",
    "    - 'Ú†Ù‚Ø¯Ø± ÙˆØ±Ø²Ø´ Ù…ÛŒÚ©Ù†ÛŒØ¯ ØŸ'\n",
    "    - 'Ø¢ÛŒØ§ Ø³ÛŒÚ¯Ø§Ø± ÛŒØ§ Ø§Ù„Ú©Ù„ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†ÛŒØ¯ØŸ'\n",
    "    - 'Ø¢ÛŒØ§ Ø¯Ø± Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ ØªØ§Ù† Ú©Ø³ÛŒ ÙØ´Ø§Ø±Ø®ÙˆÙ† ÛŒØ§ Ø³Ú©ØªÙ‡ Ú©Ø±Ø¯Ù‡ Ø§Ø³ØªØŸ'\n",
    "- K is needed for calculating the effect of salt on blood pressure.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e80359",
   "metadata": {},
   "source": [
    "### Create K-Value Assessment Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "db197e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_agent = Agent(\n",
    "    name = 'k-finder', \n",
    "    instructions = K_INSTRUCTIONS,\n",
    "    model = 'gpt-4o',\n",
    "    output_type = KBloodPressure\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bp_calc_title",
   "metadata": {},
   "source": [
    "## Blood Pressure Calculation Functions\n",
    "### Utility Function for BP Range Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c2d7861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_to_range(value: float | int) -> int:\n",
    "    \"\"\"\n",
    "    Force a number into the inclusive range [105, 180].\n",
    "    Returns an *int* (you can change to float if you need decimals).\n",
    "    \"\"\"\n",
    "    return max(105, min(180, int(value)))\n",
    "\n",
    "@function_tool\n",
    "def calculate_blood_pressure(k: int, SBP_current: int):\n",
    "\n",
    "    ten_percent_more_salt_SBP_new = clamp_to_range(SBP_current + k*math.log(1.1))\n",
    "    current_SBP_new = clamp_to_range(SBP_current + k*math.log(1))\n",
    "    ten_percent_less_salt_SBP_new = clamp_to_range(SBP_current + k*math.log(0.9 ))\n",
    "\n",
    "    return {\n",
    "        'SBP_new': {\n",
    "            'ten_percent_more_salt': ten_percent_more_salt_SBP_new,\n",
    "            'current': current_SBP_new,\n",
    "            'ten_percent_less_salt': ten_percent_less_salt_SBP_new\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bp_predict_title",
   "metadata": {},
   "source": [
    "### Calculate Immediate BP Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bp_predict_long_title",
   "metadata": {},
   "source": [
    "### Predict Long-term BP Changes (30-day projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "9fa4dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@function_tool\n",
    "def predict_blood_pressure(SBP_current: int, SBP_new_ten_precent_more: int, SBP_new_current: int, SBP_new_ten_percent_less: int):\n",
    "    '''\n",
    "        Calculate the blood pressure after 30 days based on the:\n",
    "        SBP(t) = SBP_base + Î”SBP Ã— (1 - e^( -t / Ï„ ))\n",
    "    '''\n",
    "    SBP_base = SBP_current\n",
    "    delta_SBP = SBP_new_ten_precent_more - SBP_current\n",
    "    tau = 10\n",
    "    t = 30\n",
    "\n",
    "    predicted_SBP_new_ten_precent_more = clamp_to_range(SBP_base + delta_SBP * (1 - pow(math.e, -t / tau)))\n",
    "\n",
    "    delta_SBP = SBP_new_current - SBP_current\n",
    "    predicted_SBP_new_current = clamp_to_range(SBP_base + delta_SBP * (1 - pow(math.e, -t / tau)))\n",
    "\n",
    "    delta_SBP = SBP_new_ten_percent_less - SBP_current\n",
    "    predicted_SBP_new_ten_percent_less = clamp_to_range(SBP_base + delta_SBP * (1 - pow(math.e, -t / tau)))\n",
    "\n",
    "    return {\n",
    "        'SBP_predicted': {\n",
    "            'ten_percent_more_salt': predicted_SBP_new_ten_precent_more,\n",
    "            'current': predicted_SBP_new_current,\n",
    "            'ten_percent_less_salt': predicted_SBP_new_ten_percent_less\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3931f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent Tools Configuration\n",
    "### Setup Tools for Blood Pressure Expert Agent\n",
    "\n",
    "k_agent_tool = k_agent.as_tool(tool_name='k_agent_tool', tool_description='finding k for calculating the effect of salt on bool pressure')\n",
    "tools = [k_agent_tool, calculate_blood_pressure, predict_blood_pressure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5e510e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blood Pressure Expert Agent\n",
    "### Define BP Expert Instructions\n",
    "\n",
    "def generate_BP_expert_instruction():\n",
    "    return '''\n",
    "        You are a Blood Pressure Expert AI. Your goal is to help estimate and predict a patient's systolic blood pressure (SBP) under different scenarios of salt intake over 30 days. \n",
    "\n",
    "        You have access to the following tools:\n",
    "\n",
    "        1. \"k_agent_tool\": Use this tool to determine the sensitivity parameter K based on the patient's information. K can only be 5 (normal) or 10 (hypertensive or salt-sensitive). K is needed for calculating the effect of salt on blood pressure.\n",
    "\n",
    "        2. \"calculate_blood_pressure\": Use this tool to calculate the patient's new SBP immediately after changes in salt intake. This tool takes K and the current SBP and provides SBP values for three scenarios:\n",
    "        - Ten percent more salt\n",
    "        - Current salt intake\n",
    "        - Ten percent less salt\n",
    "\n",
    "        3. \"predict_blood_pressure\": Use this tool to predict the SBP after 30 days for each scenario using a dynamic model:\n",
    "        SBP(t) = SBP_base + Î”SBP Ã— (1 - e^(-t / Ï„))\n",
    "\n",
    "        Instructions:\n",
    "\n",
    "        - Always start by using \"k_agent_tool\" to determine K from the patient's answers.\n",
    "        - Then use \"calculate_blood_pressure\" with input parameter of K which is calculated in previous state and the patient's current SBP based on the answer of the question of 'Ø¢Ø®Ø±ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©/Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø´Ù…Ø§ Ú†Ù†Ø¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ'.\n",
    "        - Finally, use \"predict_blood_pressure\" to calculate the SBP after 30 days for each scenario. The inputs of predict_blood_pressure are the following:\n",
    "            - SBP_current: based on the answer of question 'Ø¢Ø®Ø±ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©/Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø´Ù…Ø§ Ú†Ù†Ø¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ'\n",
    "            - SBP_new_ten_precent_more, SBP_new_current, SBP_new_ten_percent_less are the Immediate SBP which was calculated in predict_blood_pressure\n",
    "        - Be precise and only use the tools for calculations; do not guess numeric values.\n",
    "        - Output should clearly show in a json format and do not add further any words and sentences :\n",
    "            - calculated K with the name of k in the output json\n",
    "            - SBP_base which was used in all of the tools with SBP_base in the output json\n",
    "            - Immediate SBP for each scenario based on function of calculate_blood_pressure (the name of output should not change at all and should be SBP_new )\n",
    "            - Predicted SBP after 30 days for each scenario based on the output of predict_blood_pressure (the name of output should not change at all and must be SBP_predicted)\n",
    "\n",
    "        Patient inputs you may receive include current SBP and any relevant health/salt-sensitivity information.\n",
    "\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "c9782ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Create Blood Pressure Expert Agent\n",
    "\n",
    "def call_blood_pressure_expert():\n",
    "    blood_pressure_expert_agent = Agent(\n",
    "        name = 'blood_pressure_expert',\n",
    "        instructions= generate_BP_expert_instruction(),\n",
    "        model=\"gpt-4o\",\n",
    "        tools = tools\n",
    "    )\n",
    "\n",
    "    return blood_pressure_expert_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "5497f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execute SBP Prediction Workflow\n",
    "\n",
    "async def call_SBP_expert_agent() -> Dict[str, str]:\n",
    "    global questionsList, accepted_answers\n",
    "    prompt = ''\n",
    "    for question, ans in zip(questionsList, accepted_answers):\n",
    "        prompt += f'{question}: {ans}\\n'\n",
    "\n",
    "    prompt += \"\"\"\n",
    "        Please determine:\n",
    "        1) K (5 for normal, 10 if patient has high blood pressure or is salt-sensitive).\n",
    "        2) Immediate_SBP for three salt scenarios: 10% less, current, 10% more.\n",
    "        3) Predicted SBP after 30 days for each scenario.\n",
    "        Return results clearly labeled.\n",
    "    \"\"\"\n",
    "\n",
    "    predictor_agent = call_blood_pressure_expert()\n",
    "    result = await Runner.run(predictor_agent, prompt)\n",
    "    raw_text = result.final_output\n",
    "    print(raw_text)\n",
    "    return json.loads(raw_text.replace('```json', '').replace('```', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "c83bc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image Generation\n",
    "### Chart Image Generator Instructions\n",
    "\n",
    "def generate_chart_image_generator_instruction(immediate_SBP, predicted_SBP):\n",
    "    CHART_IMAGE_GENERATOR_INSTRUCTION = f'''\n",
    "        You are a strict and highly precise chart-rendering agent. Your task is to generate a clean, accurate data-visualization image consisting of THREE SEPARATE LINE-CHART PANELS stacked vertically:\n",
    "\n",
    "    1. Panel 1: â€œ10% Lessâ€\n",
    "    2. Panel 2: â€œCurrentâ€\n",
    "    3. Panel 3: â€œ10% Moreâ€\n",
    "\n",
    "    Each panel represents ONE scenario only.\n",
    "\n",
    "    You MUST use ONLY the numerical values provided in two structured inputs:\n",
    "    - immediate_SBP = {{ 'ten_percent_less': {immediate_SBP['ten_percent_less_salt']}, 'actual (current)': {immediate_SBP['current']}, 'ten_percent_more': {immediate_SBP['ten_percent_more_salt']} }}\n",
    "    - predicted_SBP = {{ 'ten_percent_less': {predicted_SBP['ten_percent_less_salt']}, 'actual (current)': {predicted_SBP['current']}, 'ten_percent_more': {predicted_SBP['ten_percent_more_salt']} }}\n",
    "\n",
    "    ------------------------------------------------------------\n",
    "    OVERALL VISUAL DESIGN (applies to all 3 panels)\n",
    "    ------------------------------------------------------------\n",
    "    â€¢ All three charts must have the SAME:\n",
    "    - Y-axis label: â€œSBP (mmHg)â€\n",
    "    - X-axis categories: â€œDay 0â€ (start), â€œDay 30â€ (end)\n",
    "    - Horizontal scale range: Auto-scale but must include both values.\n",
    "    â€¢ Style: Very clean, minimal, medical-grade professional.\n",
    "    â€¢ Line: Smooth, thin, with circular markers at both data points.\n",
    "    â€¢ Value labels MUST appear next to both data points.\n",
    "    â€¢ Colors:\n",
    "    - 10% Less â†’ Green\n",
    "    - Current â†’ Blue\n",
    "    - 10% More â†’ Red\n",
    "    â€¢ No extra gridlines besides major axis lines.\n",
    "\n",
    "    ------------------------------------------------------------\n",
    "    PANEL RULES (for each of the 3 diagrams)\n",
    "    ------------------------------------------------------------\n",
    "\n",
    "    ### PANEL 1 â†’ â€œ10% Lessâ€  \n",
    "    â€¢ Start at SBP = immediate_SBP.ten_percent_less  \n",
    "    â€¢ End at SBP = predicted_SBP.ten_percent_less  \n",
    "    â€¢ Draw a SINGLE line connecting Day 0 â†’ Day 30.\n",
    "    â€¢ Color: Green.\n",
    "    â€¢ Title the panel: â€œ10% Less SBP Scenarioâ€.\n",
    "\n",
    "    ### PANEL 2 â†’ â€œCurrentâ€  \n",
    "    â€¢ Start at SBP = immediate_SBP.current  \n",
    "    â€¢ End at SBP = predicted_SBP.current  \n",
    "    â€¢ Draw a SINGLE line connecting Day 0 â†’ Day 30.\n",
    "    â€¢ Color: Blue.\n",
    "    â€¢ Title the panel: â€œCurrent SBP Scenarioâ€.\n",
    "\n",
    "    ### PANEL 3 â†’ â€œ10% Moreâ€\n",
    "    â€¢ Start at SBP = immediate_SBP.ten_percent_more  \n",
    "    â€¢ End at SBP = predicted_SBP.ten_percent_more  \n",
    "    â€¢ Draw a SINGLE line connecting Day 0 â†’ Day 30.\n",
    "    â€¢ Color: Red.\n",
    "    â€¢ Title the panel: â€œ10% More SBP Scenarioâ€.\n",
    "\n",
    "    ------------------------------------------------------------\n",
    "    STRICT ACCURACY REQUIREMENTS\n",
    "    ------------------------------------------------------------\n",
    "    â€¢ You must plot EXACT given numerical values â€” no smoothing, no rounding.\n",
    "    â€¢ The Y-axis must reflect the true distance between immediate vs. predicted.\n",
    "    â€¢ If the SBP rises, line slopes upward; if it falls, slope downward; if equal, line is horizontal.\n",
    "    â€¢ Do NOT merge scenarios into one chart. Each panel = one scenario only.\n",
    "    â€¢ Panels must be visually parallel and uniformly sized.\n",
    "\n",
    "    ------------------------------------------------------------\n",
    "    OUTPUT REQUIREMENT\n",
    "    ------------------------------------------------------------\n",
    "    Produce ONE final image that contains all three panels aligned vertically in the order:\n",
    "    1. 10% Less  \n",
    "    2. Current  \n",
    "    3. 10% More  \n",
    "\n",
    "    It must look like a medical-grade report visualization: clean, aligned, precise.\n",
    "\n",
    "    '''\n",
    "\n",
    "    return CHART_IMAGE_GENERATOR_INSTRUCTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ccd981a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Digital Twin Image Prompt Generator\n",
    "\n",
    "def digital_twin_image_prompt_generator():\n",
    "    global accepted_answers, question_list\n",
    "    DIGITAL_TWIN_IMAGE_PROMPT_INSTRUCTIONS = '''\n",
    "        You are the **Digital Twin Image-Prompt Generator Agent**.\n",
    "\n",
    "        Your job:\n",
    "        - Receive the user's interview answers (age, gender, height, weight, BMI, baseline SBP, salt intake, activity level, smoking/alcohol, stress, family history, medications, current_SBP).\n",
    "        - Analyze all values and convert them into **digital-twin parameters**.\n",
    "        - Then produce a **complete and final image-generation prompt** for an external image generator model.\n",
    "\n",
    "        ### 1. Processing Rules\n",
    "        - Calculate BMI = weight / (height in meters)^2\n",
    "        - Assign a **risk color** for the human silhouette:\n",
    "        - Green = low risk\n",
    "        - Yellow = moderate risk\n",
    "        - Red = high risk\n",
    "        - Create three surrounding rings:\n",
    "        1. Salt ring â†’ intensity based on salt intake + added salt + salty food frequency\n",
    "        2. Weight ring â†’ intensity based on BMI category\n",
    "        3. Activity ring â†’ intensity based on physical activity level\n",
    "        - Predict SBP trend (simple rules):\n",
    "        - High salt or no activity â†’ predicted SBP increases\n",
    "        - Healthy habits â†’ predicted SBP decreases or stays stable\n",
    "\n",
    "        ### 2. Image Prompt Requirements\n",
    "        You must output **only the final image prompt**, describing:\n",
    "\n",
    "        - A human digital silhouette (â€œdigital twinâ€)\n",
    "        - The silhouetteâ€™s color showing the total cardiovascular risk\n",
    "        - Three circular rings around the figure:\n",
    "        - Salt ring\n",
    "        - Weight ring\n",
    "        - Activity ring\n",
    "        - Each ringâ€™s brightness/thickness scales with the user's risk levels\n",
    "        - Display text labels with:\n",
    "        - Age\n",
    "        - Gender\n",
    "        - BMI (calculated)\n",
    "        - Current SBP\n",
    "        - Predicted SBP\n",
    "        - Style:\n",
    "        - Clean\n",
    "        - Modern medical infographic\n",
    "        - High contrast\n",
    "        - Soft glow effects around rings\n",
    "\n",
    "        ### 3. Output Format\n",
    "        ALWAYS output only the **image prompt**, nothing else.\n",
    "\n",
    "        The output is meant to be fed directly into an image generation model.\n",
    "\n",
    "    '''\n",
    "    digital_twin_image_prompt_agent = Agent(\n",
    "        name='image_prompt_generator_agent',\n",
    "        model='gpt-4o',\n",
    "        instructions = DIGITAL_TWIN_IMAGE_PROMPT_INSTRUCTIONS,\n",
    "    )\n",
    "\n",
    "    return digital_twin_image_prompt_agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "ea610c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gemini Image Generation Function\n",
    "\n",
    "async def gemini_image_generator_async(prompt):\n",
    "    def sync_generate():\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-image\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(response_modalities=[types.Modality.IMAGE])\n",
    "        )\n",
    "        image_bytes = response.candidates[0].content.parts[0].inline_data.data\n",
    "        return Image.open(BytesIO(image_bytes))\n",
    "    return await asyncio.to_thread(sync_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "2a6e45f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main Chat Interface\n",
    "### Chat Function with Complete Workflow\n",
    "\n",
    "WATCH_FILM_MESSAGE = \"Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ± ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ ØªÙ…Ø§Ø´Ø§ Ú©Ù†ÛŒØ¯.\"\n",
    "\n",
    "async def chat(message, history):\n",
    "    global question_index, repeat_question\n",
    "\n",
    "    history = history or []\n",
    "\n",
    "    agent_interviewer = call_interviewer_agent()\n",
    "    result = await Runner.run(agent_interviewer, message)\n",
    "\n",
    "    print(result.final_output)\n",
    "\n",
    "    chart_image = None\n",
    "    digital_twin_image = None\n",
    "\n",
    "    if (result.final_output.is_question_being_answered):\n",
    "        question_index += 1\n",
    "        repeat_question = False\n",
    "        accepted_answers.append(result.final_output.accepted_user_response)\n",
    "        if question_index == len(questionsList):\n",
    "            agent_reply = (\n",
    "                        str(result.final_output.agent_response)\n",
    "                        + '\\n'\n",
    "                        + f'{WATCH_FILM_MESSAGE}'\n",
    "                    )\n",
    "\n",
    "            json_SBP = await call_SBP_expert_agent()\n",
    "            print(json_SBP)\n",
    "            immediate_SBP = json_SBP['SBP_new']\n",
    "            predicted_SBP = json_SBP['SBP_predicted']\n",
    "            print(immediate_SBP, predicted_SBP)\n",
    "\n",
    "            chart_image_generator_agent = digital_twin_image_prompt_generator()\n",
    "            prompt = 'These are the questions and answers of interview: \\n'\n",
    "            for question, ans in zip(questionsList, accepted_answers):\n",
    "                prompt += f'{question}: {ans}\\n'\n",
    "            image_prompt = await Runner.run(chart_image_generator_agent, prompt)\n",
    "            chart_image, digital_twin_image = await asyncio.gather(gemini_image_generator_async(generate_chart_image_generator_instruction(immediate_SBP, predicted_SBP)), gemini_image_generator_async(image_prompt.final_output))\n",
    "\n",
    "\n",
    "        else:\n",
    "            agent_reply = str(result.final_output.agent_response) + '\\n' + f'{questionsList[question_index]}'\n",
    "    else:\n",
    "        repeat_question = True\n",
    "        agent_reply = str(result.final_output.agent_response)\n",
    "\n",
    "    history.append((message, agent_reply))\n",
    "\n",
    "    video_url = ''\n",
    "    if (question_index == len(questionsList)):\n",
    "        video_url = 'https://www.aparat.com/video/video/embed/videohash/pl2Ww/vt/frame'\n",
    "\n",
    "    video_output = f\"\"\"<div style=\"width:100%; height:400px;\">\n",
    "                            <iframe\n",
    "                                style=\"width:100%; height:100%; border:0;\"\n",
    "                                src=\"{video_url}\"\n",
    "                                allowfullscreen>\n",
    "                            </iframe>\n",
    "                        </div>\n",
    "                    \"\"\"    \n",
    "\n",
    "    return history, \"\", video_output, chart_image, digital_twin_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "39836b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reset Function\n",
    "\n",
    "def reset_all():\n",
    "    global question_index, repeat_question, accepted_answers\n",
    "    question_index = 0\n",
    "    repeat_question = False\n",
    "    accepted_answers = []\n",
    "\n",
    "    return \"\", \"\", \"\", None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e62147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jp/7nrzb78x6_x47df5nzv_fv_r0000gn/T/ipykernel_52032/3195125911.py:6: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Ú¯ÙØªÚ¯Ùˆ\", rtl=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_question_being_answered=False accepted_user_response='' agent_response='Ø³Ù„Ø§Ù…! Ø³Ù† Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ'\n",
      "is_question_being_answered=True accepted_user_response='Û²Ûµ' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯. Ù…ØªØ´Ú©Ø±Ù…!'\n",
      "is_question_being_answered=True accepted_user_response='Ù…Ø±Ø¯' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ú©Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ø§Ø¯ÛŒØ¯.'\n",
      "is_question_being_answered=True accepted_user_response='Û±Û²/Û¹' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯: Û±Û²/Û¹'\n",
      "is_question_being_answered=True accepted_user_response='Ù…ØªÙˆØ³Ø·' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§: \"Ù…ØªÙˆØ³Ø·\" Ø«Ø¨Øª Ø´Ø¯.'\n",
      "is_question_being_answered=True accepted_user_response='Ø®ÛŒØ±' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ø§Ø² Ù¾Ø§Ø³Ø®\\u200cØªØ§Ù†.'\n",
      "is_question_being_answered=True accepted_user_response='Ø³Ù‡ Ø¨Ø§Ø±' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ø³Ù¾Ø§Ø³Ú¯Ø²Ø§Ø±Ù….'\n",
      "is_question_being_answered=True accepted_user_response='Û´Ù„ÛŒÙˆØ§Ù†' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯. Ø³Ù¾Ø§Ø³Ú¯Ø²Ø§Ø±Ù….'\n",
      "is_question_being_answered=True accepted_user_response='Ø¨Ù„Ù‡ Ø²ÛŒØ§Ø¯ Ù‚Ù‡ÙˆÙ‡ Ù…ÛŒØ®ÙˆØ±Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ø§Ø² Ù¾Ø§Ø³Ø®ØªÙˆÙ†!'\n",
      "is_question_being_answered=True accepted_user_response='Ù…Ù†Ø¸Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯: Ø´Ù…Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ù…Ù†Ø¸Ù… ÙˆØ±Ø²Ø´ Ù…ÛŒ\\u200cÚ©Ù†ÛŒØ¯.'\n",
      "is_question_being_answered=True accepted_user_response='Û±Û·Û°' agent_response='Ù‚Ø¯ Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ø§Ø² Ù‡Ù…Ú©Ø§Ø±ÛŒ Ø´Ù…Ø§.'\n",
      "is_question_being_answered=True accepted_user_response='Û¸Û°' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯.'\n",
      "is_question_being_answered=True accepted_user_response='Ø®ÛŒØ±' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯. Ø§Ø² Ø´Ù…Ø§ Ù…ØªØ´Ú©Ø±Ù….'\n",
      "is_question_being_answered=True accepted_user_response='Ù‡ÛŒÚ† Ø¯Ø§Ø±ÙˆÛŒÛŒ Ù…ØµØ±Ù Ù†Ù…ÛŒÚ©Ù†Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ø§Ø² Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ù…ØªØ´Ú©Ø±Ù….'\n",
      "is_question_being_answered=True accepted_user_response='Ù¾Ø¯Ø±Ù… ÙØ´Ø§Ø±Ø®ÙˆÙ† Ø¯Ø§Ø±Ø¯' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ø§Ø² Ø´Ù…Ø§.'\n",
      "is_question_being_answered=True accepted_user_response='Ú©Ù…' agent_response='Ù¾Ø§Ø³Ø®ØªØ§Ù† ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ø¨Ø§Ø¨Øª Ø§Ø·Ù„Ø§Ø¹Ø§ØªØªØ§Ù†.'\n",
      "is_question_being_answered=True accepted_user_response='Ø®ÛŒØ±' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯.'\n",
      "```json\n",
      "{\n",
      "    \"k\": 5,\n",
      "    \"SBP_base\": 120,\n",
      "    \"SBP_new\": {\n",
      "        \"ten_percent_more_salt\": 120,\n",
      "        \"current\": 120,\n",
      "        \"ten_percent_less_salt\": 119\n",
      "    },\n",
      "    \"SBP_predicted\": {\n",
      "        \"ten_percent_more_salt\": 120,\n",
      "        \"current\": 120,\n",
      "        \"ten_percent_less_salt\": 119\n",
      "    }\n",
      "}\n",
      "```\n",
      "{'k': 5, 'SBP_base': 120, 'SBP_new': {'ten_percent_more_salt': 120, 'current': 120, 'ten_percent_less_salt': 119}, 'SBP_predicted': {'ten_percent_more_salt': 120, 'current': 120, 'ten_percent_less_salt': 119}}\n",
      "{'ten_percent_more_salt': 120, 'current': 120, 'ten_percent_less_salt': 119} {'ten_percent_more_salt': 120, 'current': 120, 'ten_percent_less_salt': 119}\n",
      "is_question_being_answered=False accepted_user_response='' agent_response='Ø³Ù„Ø§Ù…! Ø³Ù† Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ'\n",
      "is_question_being_answered=True accepted_user_response='Û²Û¶' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯: Û²Û¶ Ø³Ø§Ù„Ù‡ Ù‡Ø³ØªÛŒØ¯. Ù…ØªØ´Ú©Ø±Ù…!'\n",
      "is_question_being_answered=True accepted_user_response='Ù…Ø±Ø¯' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯.'\n",
      "is_question_being_answered=True accepted_user_response='Û±Û³/Û¹' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ø¨Ø³ÛŒØ§Ø± Ø®ÙˆØ¨.'\n",
      "is_question_being_answered=True accepted_user_response='Ø²ÛŒØ§Ø¯' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ø§Ø² Ø´Ù…Ø§!'\n",
      "is_question_being_answered=True accepted_user_response='Ø²ÛŒØ§Ø¯ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒÚ©Ù†Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯.'\n",
      "is_question_being_answered=True accepted_user_response='Û³ Ø¨Ø§Ø±' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯.'\n",
      "is_question_being_answered=True accepted_user_response='ÛµÙ„ÛŒÙˆØ§Ù†' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ†! Ø­Ø§Ù„Ø§ Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¯Ø§Ø±ÛŒØ¯ØŒ Ø¨Ù¾Ø±Ø³ÛŒØ¯.'\n",
      "is_question_being_answered=True accepted_user_response='Ù‚Ù‡ÙˆÙ‡ Ù…ØµØ±Ù Ù…ÛŒÚ©Ù†Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ø§Ø² Ù¾Ø§Ø³Ø® Ø´Ù…Ø§.'\n",
      "is_question_being_answered=True accepted_user_response='Ù…Ù†Ø¸Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯.'\n",
      "is_question_being_answered=True accepted_user_response='Û±Û·Û°' agent_response='Ù‚Ø¯ Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯ØŒ Û±Û·Û° Ø³Ø§Ù†ØªÛŒ\\u200cÙ…ØªØ±. Ø¨Ø§ ØªØ´Ú©Ø± Ø§Ø² Ù¾Ø§Ø³Ø® Ø´Ù…Ø§.'\n",
      "is_question_being_answered=True accepted_user_response='Û¹Û³' agent_response='Ù…Ù…Ù†ÙˆÙ†ØŒ Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯.'\n",
      "is_question_being_answered=True accepted_user_response='Ù†Ø¯Ø§Ø±Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ø§Ø² Ø´Ù…Ø§.'\n",
      "is_question_being_answered=True accepted_user_response='Ù‡ÛŒÚ† Ø¯Ø§Ø±ÙˆÛŒÛŒ Ù…ØµØ±Ù Ù†Ù…ÛŒÚ©Ù†Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯ Ú©Ù‡ Ù‡ÛŒÚ† Ø¯Ø§Ø±ÙˆÛŒÛŒ Ù…ØµØ±Ù Ù†Ù…ÛŒ\\u200cÚ©Ù†ÛŒØ¯.'\n",
      "is_question_being_answered=True accepted_user_response='Ù…Ø§Ø¯Ø±Ù… ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø¯Ø§Ø±Ø¯' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ† Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹ Ø¯Ø§Ø¯ÛŒØ¯.'\n",
      "is_question_being_answered=True accepted_user_response='Ú©Ù…' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø³Ø·Ø­ Ø§Ø³ØªØ±Ø³ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯. Ù…Ù…Ù†ÙˆÙ†!'\n",
      "is_question_being_answered=True accepted_user_response='Ø¨Ù„Ù‡' agent_response='Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯.'\n",
      "```json\n",
      "{\n",
      "    \"k\": 10,\n",
      "    \"SBP_base\": 130,\n",
      "    \"SBP_new\": {\n",
      "        \"ten_percent_more_salt\": 130,\n",
      "        \"current\": 130,\n",
      "        \"ten_percent_less_salt\": 129\n",
      "    },\n",
      "    \"SBP_predicted\": {\n",
      "        \"ten_percent_more_salt\": 130,\n",
      "        \"current\": 130,\n",
      "        \"ten_percent_less_salt\": 129\n",
      "    }\n",
      "}\n",
      "```\n",
      "{'k': 10, 'SBP_base': 130, 'SBP_new': {'ten_percent_more_salt': 130, 'current': 130, 'ten_percent_less_salt': 129}, 'SBP_predicted': {'ten_percent_more_salt': 130, 'current': 130, 'ten_percent_less_salt': 129}}\n",
      "{'ten_percent_more_salt': 130, 'current': 130, 'ten_percent_less_salt': 129} {'ten_percent_more_salt': 130, 'current': 130, 'ten_percent_less_salt': 129}\n"
     ]
    }
   ],
   "source": [
    "## Gradio Interface\n",
    "### Create Web Interface\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"<h1 style='text-align:center; direction:rtl;'>ğŸ§  Ø¯Ø³ØªÛŒØ§Ø± Ù…ØµØ§Ø­Ø¨Ù‡ Ø³Ù„Ø§Ù…Øª</h1>\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot(label=\"Ú¯ÙØªÚ¯Ùˆ\", rtl=True)\n",
    "            msg = gr.Textbox(label=\"Ù¾ÛŒØ§Ù… Ø´Ù…Ø§\", placeholder=\"Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯...\", rtl=True)\n",
    "            reset_btn = gr.Button(\"ğŸ”„ Ø±ÛŒØ³Øª\")\n",
    "    with gr.Row():\n",
    "        chart_image = gr.Image(label=\"ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± ÙØ´Ø§Ø± Ø®ÙˆÙ†\")\n",
    "        video_output = gr.HTML(label=\"ÙˆÛŒØ¯ÛŒÙˆ\")\n",
    "        digital_twin_image = gr.Image(label=\"ğŸ§â€â™‚ï¸ ØªØµÙˆÛŒØ± Ø¯ÛŒØ¬ÛŒØªØ§Ù„ ØªÙˆØ¦ÛŒÙ†\")\n",
    "    \n",
    "            \n",
    "\n",
    "    # Message submit\n",
    "    msg.submit(\n",
    "        chat,\n",
    "        [msg, chatbot],\n",
    "        [chatbot, msg, video_output, chart_image, digital_twin_image]\n",
    "    )\n",
    "\n",
    "    # Reset button click\n",
    "    reset_btn.click(\n",
    "        reset_all,\n",
    "        inputs=[],\n",
    "        outputs=[chatbot, msg, video_output, chart_image, digital_twin_image]\n",
    "    )\n",
    "\n",
    "demo.launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "1b98dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     gr.Markdown(\"# ğŸ§  Health Interview Assistant\")\n",
    "    \n",
    "#     with gr.Row():\n",
    "#         with gr.Column():\n",
    "#             chatbot = gr.Chatbot()\n",
    "#             msg = gr.Textbox(label=\"Your message\")\n",
    "        \n",
    "#         with gr.Column():\n",
    "#             with gr.Row():\n",
    "#                 video_output = gr.HTML(label=\"Video Output\")\n",
    "#             with gr.Row():\n",
    "#                 gr.Markdown(\"Second half for future content\")\n",
    "        \n",
    "    \n",
    "    \n",
    "#     msg.submit(chat, [msg, chatbot], [chatbot, msg, video_output])\n",
    "\n",
    "# demo.launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a7b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
